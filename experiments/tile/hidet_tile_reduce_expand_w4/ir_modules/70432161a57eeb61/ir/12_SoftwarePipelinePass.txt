#layout: block(shape=[64, 32], size_per_thread=[1, 4], thread_per_warp=[4, 8], warps_per_block=[4, 1])
#layout1: block(shape=[64, 32], size_per_thread=[1, 1], thread_per_warp=[1, 32], warps_per_block=[4, 1])
#layout2: block(shape=[64, 16], size_per_thread=[1, 4], thread_per_warp=[8, 4], warps_per_block=[4, 1])
#layout3: block(shape=[64, 1], size_per_thread=[1, 1], thread_per_warp=[32, 1], warps_per_block=[2, 2])
#layout4: block(shape=[64, 16], size_per_thread=[1, 1], thread_per_warp=[32, 1], warps_per_block=[2, 2])

def over_sub_load(
    a: float32*,
    b: float32*,
    c: float32*
)
    # kind: cuda_tile
    # cuda.block_dim: 128
    # cuda.grid_dim: 1
    let cvt: float32*[64, 32, #layout] = create((a + ((i * 32) + j)), shape=[64, 32], axes=[i, j], layout=#layout)
    let load: float32[64, 32, #layout] = load(cvt)
    let a1: float32[64, 32, #layout1] = convert_layout(load, layout=#layout1)
    let cvt_0: float32*[64, 16, #layout2] = create((b + ((i_0 * 16) + j_0)), shape=[64, 16], axes=[i_0, j_0], layout=#layout2)
    let load_0: float32[64, 16, #layout2] = load(cvt_0)
    let reduce_op: float32[64, flatten_block(#layout1, axis=1)] = reduce_op(a1, axis=1, keepdims=False, kind=ReduceKind.sum, layout=flatten_block(#layout1, axis=1))
    let cvt_1: float32[64, flatten_block(#layout3, axis=1)] = convert_layout(reduce_op, layout=flatten_block(#layout3, axis=1))
    let expand_dims: float32[64, 1, #layout3] = expand_dims(cvt_1, axis=1, layout=#layout3)
    let cvt_2: float32[64, 1, #layout4] = convert_layout(expand_dims, layout=#layout4)
    let broadcast: float32[64, 16, #layout4] = broadcast(cvt_2, shape=[64, 16], layout=#layout4)
    let cvt_3: float32*[64, 16, #layout2] = create((c + ((i_1 * 16) + j_1)), shape=[64, 16], axes=[i_1, j_1], layout=#layout2)
    let cvt_4: float32[64, 16, #layout2] = convert_layout(broadcast, layout=#layout2, scope=register)
    let cvt_5: float32[64, 16, #layout2] = multiply(load_0, cvt_4)
    store(cvt_3, cvt_5)

