//
// Generated by LLVM NVPTX Back-End
//

.version 7.5
.target sm_86
.address_size 64

	// .globl	test_0d1d2d
.extern .shared .align 1 .b8 global_smem[];

.visible .entry test_0d1d2d(
	.param .u64 test_0d1d2d_param_0,
	.param .u64 test_0d1d2d_param_1,
	.param .u64 test_0d1d2d_param_2
)
.maxntid 32, 1, 1
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<42>;
	.reg .f32 	%f<25>;
	.reg .b64 	%rd<16>;

	ld.param.u64 	%rd7, [test_0d1d2d_param_0];
	ld.param.u64 	%rd8, [test_0d1d2d_param_1];
	mov.u32 	%r19, %tid.x;
	and.b32  	%r20, %r19, 31;
	ld.param.u64 	%rd9, [test_0d1d2d_param_2];
	and.b32  	%r21, %r19, 15;
	bfe.u32 	%r22, %r19, 2, 3;
	shr.u32 	%r23, %r19, 2;
	and.b32  	%r24, %r23, 24;
	or.b32  	%r25, %r22, %r24;
	shl.b32 	%r26, %r19, 2;
	and.b32  	%r27, %r26, 12;
	mul.wide.u32 	%rd10, %r20, 4;
	add.s64 	%rd1, %rd7, %rd10;
	mul.wide.u32 	%rd11, %r21, 4;
	add.s64 	%rd2, %rd8, %rd11;
	mov.pred 	%p1, -1;
	@%p1 ld.global.b32 { %r1 }, [ %rd1 + 0 ];
	@%p1 ld.global.b32 { %r2 }, [ %rd2 + 0 ];
	shl.b32 	%r28, %r20, 2;
	mov.u32 	%r29, global_smem;
	add.s32 	%r30, %r29, %r28;
	st.shared.u32 	[%r30], %r1;
	bar.sync 	0;
	shl.b32 	%r31, %r25, 2;
	add.s32 	%r32, %r29, %r31;
	ld.shared.f32 	%f1, [%r32];
	ld.shared.f32 	%f2, [%r32+32];
	ld.shared.f32 	%f3, [%r32+64];
	ld.shared.f32 	%f4, [%r32+96];
	bar.sync 	0;
	shl.b32 	%r33, %r21, 2;
	add.s32 	%r34, %r29, %r33;
	st.shared.u32 	[%r34], %r2;
	bar.sync 	0;
	shl.b32 	%r35, %r27, 2;
	add.s32 	%r36, %r29, %r35;
	ld.shared.f32 	%f5, [%r36];
	ld.shared.f32 	%f6, [%r36+4];
	ld.shared.f32 	%f7, [%r36+8];
	ld.shared.f32 	%f8, [%r36+12];
	add.f32 	%f9, %f1, %f5;
	add.f32 	%f10, %f1, %f6;
	add.f32 	%f11, %f1, %f7;
	add.f32 	%f12, %f1, %f8;
	add.f32 	%f13, %f2, %f5;
	add.f32 	%f14, %f2, %f6;
	add.f32 	%f15, %f2, %f7;
	add.f32 	%f16, %f2, %f8;
	add.f32 	%f17, %f3, %f5;
	add.f32 	%f18, %f3, %f6;
	add.f32 	%f19, %f3, %f7;
	add.f32 	%f20, %f3, %f8;
	add.f32 	%f21, %f4, %f5;
	add.f32 	%f22, %f4, %f6;
	add.f32 	%f23, %f4, %f7;
	add.f32 	%f24, %f4, %f8;
	shl.b32 	%r37, %r25, 4;
	or.b32  	%r38, %r37, %r27;
	add.s32 	%r39, %r38, 128;
	add.s32 	%r40, %r38, 256;
	add.s32 	%r41, %r38, 384;
	mul.wide.u32 	%rd12, %r38, 4;
	add.s64 	%rd3, %rd9, %rd12;
	mul.wide.u32 	%rd13, %r39, 4;
	add.s64 	%rd4, %rd9, %rd13;
	mul.wide.u32 	%rd14, %r40, 4;
	add.s64 	%rd5, %rd9, %rd14;
	mul.wide.u32 	%rd15, %r41, 4;
	add.s64 	%rd6, %rd9, %rd15;
	mov.b32 	%r3, %f9;
	mov.b32 	%r4, %f10;
	mov.b32 	%r5, %f11;
	mov.b32 	%r6, %f12;
	@%p1 st.global.v4.b32 [ %rd3 + 0 ], { %r3, %r4, %r5, %r6 };
	mov.b32 	%r7, %f13;
	mov.b32 	%r8, %f14;
	mov.b32 	%r9, %f15;
	mov.b32 	%r10, %f16;
	@%p1 st.global.v4.b32 [ %rd4 + 0 ], { %r7, %r8, %r9, %r10 };
	mov.b32 	%r11, %f17;
	mov.b32 	%r12, %f18;
	mov.b32 	%r13, %f19;
	mov.b32 	%r14, %f20;
	@%p1 st.global.v4.b32 [ %rd5 + 0 ], { %r11, %r12, %r13, %r14 };
	mov.b32 	%r15, %f21;
	mov.b32 	%r16, %f22;
	mov.b32 	%r17, %f23;
	mov.b32 	%r18, %f24;
	@%p1 st.global.v4.b32 [ %rd6 + 0 ], { %r15, %r16, %r17, %r18 };
	ret;

}
